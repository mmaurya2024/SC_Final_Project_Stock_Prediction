# Import necessary libraries
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler

# Get the ticker object for Apple Inc.
Apple_Inc = yf.Ticker("AAPL")

# Retrieve the company information
Apple_Inc.info

# Assign the ticker object to a variable
ticker = Apple_Inc

# Retrieve the stock history for the last 5 days
Apple_Inc.history(period='5d')

# Retrieve the stock history from 2001-01-19 to 2024-05-06, excluding the actions data
df = Apple_Inc.history(start='2001-01-19', end='2024-05-06', actions=False)

# Display the dataframe
df

# Get the index (dates) of the dataframe
df.index

# Get the shape of the dataframe
df.shape

# Check for any missing values in the dataframe
df.isnull().sum()

# Drop the unnecessary columns (Open, High, Volume, Low)
df = df.drop(['Open', 'High', 'Volume', 'Low'], axis=1)

# Display the last few rows of the updated dataframe
df.tail()

# Set the figure size for the plots
plt.rcParams["figure.figsize"] = (20, 7)

# Choose the plotting style
import matplotlib.pyplot as plt
plt.style.use('dark_background')

# Plot the price of Apple Inc. over the years
plt.figure(figsize=(20, 7))
plt.title("Price of Apple Inc. over the years")
plt.plot(df['2019-09-18':'2024-05-06'])
plt.ylabel("Price in INR")
plt.xlabel("Time")

# Plot the price of Apple Inc. in the year 2021
plt.figure(figsize=(20, 7))
plt.title("Price of Apple Inc. in year 2021")
plt.plot(df['2021-01-01':'2024-05-06'])
plt.ylabel("Price in INR")
plt.xlabel("Time")

# Convert the dataframe to a numpy array
data = df.values

# Get the length of the data
len(data)

# Calculate the length of the training data (92% of the total data)
train_len = math.ceil(len(data) * 0.92)

# Create a MinMaxScaler object to scale the data between 0 and 1
min_max_scalar = MinMaxScaler(feature_range=(0, 1))

# Scale the data
scaled_data = min_max_scalar.fit_transform(data)

# Get the length of the scaled data
len(scaled_data)

# Extract the training data
train_data = scaled_data[0:train_len, :]

# Set the sequence length for the LSTM model
interval = 60

# Create the input (X_train) and output (y_train) sequences for the LSTM model
x_train = []
y_train = []
for i in range(interval, len(train_data)):
    x_train.append(train_data[i - interval:i, 0])
    y_train.append(train_data[i, 0])

# Convert the lists to numpy arrays
x_train, y_train = np.array(x_train), np.array(y_train)

# Reshape the input data to fit the LSTM model
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

# Build the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(units=50))
model.add(Dense(50))
model.add(Dense(1))

# Compile the model
model.compile(optimizer="adam", loss="mean_squared_error")

# Train the model
history = model.fit(x_train, y_train, batch_size=64, epochs=10)

# Prepare the test data
test_data = scaled_data[train_len - interval:, :]
x_test = []
y_test = data[train_len:, :]
for i in range(interval, len(test_data)):
    x_test.append(test_data[i - interval:i, 0])

# Convert the test data to a numpy array and reshape it
x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

# Make predictions on the test data
predictions = model.predict(x_test)

# Inverse transform the predictions to get the actual values
predictions = min_max_scalar.inverse_transform(predictions)

# Calculate the root mean squared error (RMSE) of the predictions
rmse_error = np.sqrt(np.mean(predictions - y_test) ** 2)

# Split the original dataframe into training and validation sets
train_data = df[0:train_len]
valid_data = df[train_len:]

# Add the predictions to the validation dataframe
valid_data['predictions'] = predictions

# Plot the actual and predicted prices
plt.figure(figsize=(20, 7))
plt.title("Model Prediction vs Actual Price")
plt.xlabel("Date", fontsize=18)
plt.ylabel("Price in INR(in Million)", fontsize=18)
plt.plot(train_data['Close'])
plt.plot(valid_data['Close'])
plt.plot(valid_data['predictions'])
plt.legend(['Train', 'Actual Price', 'Model Prediction'], loc='upper left', fontsize=15)
plt.show()

# Prepare the data for future prediction
df_test = Apple_Inc.history(start='2001-01-19', end='2024-05-06', actions=False)
columns_to_drop = ['Open', 'High', 'Volume', 'Low']
if all(col in df_test.columns for col in columns_to_drop):
    df_test = df_test.drop(columns_to_drop, axis=1)
test_value = df_test[-60:].values
test_value = min_max_scalar.transform(test_value)
test = []
test.append(test_value)
test = np.array(test)

# Make predictions for the next 3 days
predictions = []
for _ in range(3):
    tomorrow_prediction = model.predict(test)
    tomorrow_prediction = min_max_scalar.inverse_transform(tomorrow_prediction)
    predictions.append(tomorrow_prediction)
    test = np.append(test[:, 1:, :], np.reshape(tomorrow_prediction, (tomorrow_prediction.shape[0], tomorrow_prediction.shape[1], 1)), axis=1)

predictions = np.concatenate(predictions)

# Save the trained model
model.save("Apple_Inc.h5")
